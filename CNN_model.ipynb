{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de imágenes con TensorFlow. REDES NEURONALES CONVOLUCIONALES (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install pandas \n",
    "#!pip install tqdm \n",
    "#!pip install scikit-learn \n",
    "#!pip install scikit-image\n",
    "#!pip install imblearn\n",
    "#!pip install import-ipynb\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm #barra de progreso\n",
    "import cv2\n",
    "\n",
    "#para redimensionar\n",
    "import sklearn\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "\n",
    "import random\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "#para cargar imágenes desde internet usaremos estas librerías\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesado: redimensionado 150x150, escala de grises (eliminar capa de color) y conversión a array\n",
    "def preprocess(image):\n",
    "    image = skimage.transform.resize(image, (150,150,3), mode = 'constant', anti_aliasing=True)\n",
    "    image = rgb2gray(image)\n",
    "    image_array = np.asarray(image)\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "def get_images(dir): #dir = chest_xray/train/ o chest_xray/test/\n",
    "    IMAGES = []\n",
    "    LABELS = []\n",
    "    \n",
    "    for subdir in os.listdir(dir): #lista de subdirectorios en train/ o test/ -> ['NORMAL', 'PNEUMONIA']\n",
    "        if not subdir.startswith('.'):\n",
    "            if subdir in ['NORMAL']:\n",
    "                label = 0\n",
    "            elif subdir in ['PNEUMONIA']:\n",
    "                label = 1\n",
    "            else: \n",
    "                label = 2\n",
    "                    \n",
    "            for image_name in tqdm(os.listdir(dir+subdir)): #barra de progreso\n",
    "                image = cv2.imread(dir + subdir + '/' + image_name) #lectura\n",
    "                if image is not None:\n",
    "                    #bloque de preprocesado\n",
    "                    image_array = preprocess(image)    \n",
    "                                 \n",
    "                    #add a listas de arrays y de labels\n",
    "                    IMAGES.append(image_array) \n",
    "                    LABELS.append(label) \n",
    "        \n",
    "    IMAGES = np.asarray(IMAGES)\n",
    "    LABELS = np.asarray(LABELS)\n",
    "    return IMAGES, LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1342/1342 [17:46<00:00,  1.26it/s]\n",
      "100%|██████████| 1342/1342 [04:55<00:00,  4.55it/s]\n",
      "100%|██████████| 234/234 [03:24<00:00,  1.14it/s]\n",
      "100%|██████████| 390/390 [01:15<00:00,  5.17it/s]\n"
     ]
    }
   ],
   "source": [
    "LOADED = True\n",
    "if LOADED == False:\n",
    "    x_train, y_train = get_images(\"chest_xray/train/\") #nº de imgs normal = nº imgs pneu\n",
    "    x_test, y_test = get_images(\"chest_xray/test/\") #no dimensionados\n",
    "    \n",
    "    #almacenamiento de arrays en archivos\n",
    "    np.save('xtrain.npy', x_train)\n",
    "    np.save('ytrain.npy', y_train)\n",
    "    np.save('xtest.npy', x_test)\n",
    "    np.save('ytest.npy', y_test)            \n",
    "    \n",
    "else:\n",
    "    x_train = np.load('xtrain.npy')\n",
    "    y_train = np.load('ytrain.npy')\n",
    "    x_test = np.load('xtest.npy')\n",
    "    y_test = np.load('ytest.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(len(x_train),150,150,1)\n",
    "x_test = x_test.reshape(len(x_test),150,150,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición del modelo de CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 64)      640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18496)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,496\n",
      "Trainable params: 74,496\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# 1) Se crea un mapa o array de valores más pequeño que caracteriza a la imagen\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
    "\n",
    "# 2) Se aplica un filtro MAX (obtiene el valor máximo de cada sección de píxeles) para obtener una capa de reducción o imagen más pequeña\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "model.summary() #resumen de la estructura de la red neuronal\n",
    "#los parámetros son los pesos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
