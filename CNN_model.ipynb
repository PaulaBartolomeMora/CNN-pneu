{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de imágenes con TensorFlow. REDES NEURONALES CONVOLUCIONALES (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install pandas \n",
    "#!pip install tqdm \n",
    "#!pip install scikit-learn \n",
    "#!pip install scikit-image\n",
    "#!pip install imblearn\n",
    "#!pip install import-ipynb\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm #barra de progreso\n",
    "import cv2\n",
    "\n",
    "#para redimensionar\n",
    "import sklearn\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "\n",
    "import random\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "#para cargar imágenes desde internet usaremos estas librerías\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesado: redimensionado 150x150, escala de grises (eliminar capa de color) y conversión a array\n",
    "def preprocess(image):\n",
    "    image = skimage.transform.resize(image, (150,150,3), mode = 'constant', anti_aliasing=True)\n",
    "    image = rgb2gray(image)\n",
    "    image_array = np.asarray(image)\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "def get_images(dir): #dir = chest_xray/train/ o chest_xray/test/\n",
    "    IMAGES = []\n",
    "    LABELS = []\n",
    "    \n",
    "    for subdir in os.listdir(dir): #lista de subdirectorios en train/ o test/ -> ['NORMAL', 'PNEUMONIA']\n",
    "        if not subdir.startswith('.'):\n",
    "            if subdir in ['NORMAL']:\n",
    "                label = 0\n",
    "            elif subdir in ['PNEUMONIA']:\n",
    "                label = 1\n",
    "            else: \n",
    "                label = 2\n",
    "                    \n",
    "            for image_name in tqdm(os.listdir(dir+subdir)): #barra de progreso\n",
    "                image = cv2.imread(dir + subdir + '/' + image_name) #lectura\n",
    "                if image is not None:\n",
    "                    #bloque de preprocesado\n",
    "                    image_array = preprocess(image)    \n",
    "                                 \n",
    "                    #add a listas de arrays y de labels\n",
    "                    IMAGES.append(image_array) \n",
    "                    LABELS.append(label) \n",
    "        \n",
    "    IMAGES = np.asarray(IMAGES)\n",
    "    LABELS = np.asarray(LABELS)\n",
    "    return IMAGES, LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOADED = True\n",
    "if LOADED == False:\n",
    "    x_train, y_train = get_images(\"chest_xray/train/\") #nº de imgs normal = nº imgs pneu\n",
    "    x_test, y_test = get_images(\"chest_xray/test/\") #no dimensionados\n",
    "    \n",
    "    #almacenamiento de arrays en archivos\n",
    "    np.save('xtrain.npy', x_train)\n",
    "    np.save('ytrain.npy', y_train)\n",
    "    np.save('xtest.npy', x_test)\n",
    "    np.save('ytest.npy', y_test)            \n",
    "    \n",
    "else:\n",
    "    x_train = np.load('xtrain.npy')\n",
    "    y_train = np.load('ytrain.npy')\n",
    "    x_test = np.load('xtest.npy')\n",
    "    y_test = np.load('ytest.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(len(x_train),150,150,1)\n",
    "x_test = x_test.reshape(len(x_test),150,150,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición del modelo de CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 148, 148, 64)      640       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 74, 74, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 72, 72, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 34, 34, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 17, 17, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 15, 15, 64)        36928     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 14400)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                921664    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,033,218\n",
      "Trainable params: 1,033,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# 1) Se crea un mapa o array de valores más pequeño que caracteriza a la imagen\n",
    "#    64 filtros, tamaño 3x3, función de activación rectificadora (relu)\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
    "\n",
    "# 2) Se aplica un filtro MAX (obtiene el valor máximo de cada sección de píxeles) para obtener una capa de reducción o imagen más pequeña\n",
    "#    Ventana que recorre el mapa de características, máximo de valores, 2x2\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "\n",
    "#capas internas\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "# 3) Flatening: se deja como una capa plana de una dimensión con todos los valores\n",
    "#    64 valores a la entrada, 2 neuronas a la salida [NORMAL, PNEUMONIA]\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu')) #capa densa, función de activación rectificadora (relu)\n",
    "model.add(layers.Dense(2, activation='softmax')) #capa densa, función de activación softmax siempre a la salida\n",
    "\n",
    "\n",
    "\n",
    "model.summary() #resumen de la estructura de la red neuronal\n",
    "#los parámetros son los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se compila el modelo\n",
    "model.compile(\n",
    "    optimizer = 'adam', #se optimiza con el método de adam que es mejor que el gradiente descendente\n",
    "    loss = 'sparse_categorical_crossentropy', #función de pérdidas, probabilidad de que una prenda pertenezca a una clase\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "84/84 [==============================] - 117s 1s/step - loss: 0.4831 - accuracy: 0.7435\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 76s 903ms/step - loss: 0.2056 - accuracy: 0.9187\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 132s 2s/step - loss: 0.1493 - accuracy: 0.9411\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 235s 3s/step - loss: 0.1129 - accuracy: 0.9567\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 219s 3s/step - loss: 0.0907 - accuracy: 0.9679\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 208s 2s/step - loss: 0.0939 - accuracy: 0.9616\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 200s 2s/step - loss: 0.0726 - accuracy: 0.9720\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 116s 1s/step - loss: 0.0581 - accuracy: 0.9773\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 77s 920ms/step - loss: 0.0662 - accuracy: 0.9750\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 78s 929ms/step - loss: 0.0853 - accuracy: 0.9661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1788010c880>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10) #una época equivale a un procesamiento completo de todas las imágenes del dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
